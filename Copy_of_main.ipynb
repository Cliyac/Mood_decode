{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNv51f8sOS6ykjDu53JpAdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cliyac/Mood_decode/blob/main/Copy_of_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7sJy0WH90IgB",
        "outputId": "1d747179-06e6-46d2-9874-7e3e0bff5ada"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2d28f189-f1b5-4c43-9f24-fea3091ec210\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2d28f189-f1b5-4c43-9f24-fea3091ec210\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving main.py to main.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'main.py': b'#!/usr/bin/env python3\\r\\n\"\"\"\\r\\nMoodDecode: NLP API for Emotion Analysis, Crisis Detection, and Text Summarization\\r\\n\"\"\"\\r\\n\\r\\nfrom flask import Flask, request, jsonify\\r\\nimport re\\r\\nimport nltk\\r\\nfrom nltk.sentiment import SentimentIntensityAnalyzer\\r\\nfrom nltk.corpus import stopwords\\r\\nfrom nltk.tokenize import word_tokenize, sent_tokenize\\r\\nfrom collections import Counter\\r\\nimport heapq\\r\\nimport logging\\r\\n\\r\\n# Download required NLTK data\\r\\ntry:\\r\\n    nltk.data.find(\\'tokenizers/punkt\\')\\r\\n    nltk.data.find(\\'corpora/stopwords\\')\\r\\n    nltk.data.find(\\'vader_lexicon\\')\\r\\nexcept LookupError:\\r\\n    nltk.download(\\'punkt\\')\\r\\n    nltk.download(\\'stopwords\\')\\r\\n    nltk.download(\\'vader_lexicon\\')\\r\\n\\r\\napp = Flask(__name__)\\r\\napp.config[\\'JSON_SORT_KEYS\\'] = False\\r\\n\\r\\n# Initialize NLTK components\\r\\nsia = SentimentIntensityAnalyzer()\\r\\nstop_words = set(stopwords.words(\\'english\\'))\\r\\n\\r\\n# Configure logging\\r\\nlogging.basicConfig(level=logging.INFO)\\r\\nlogger = logging.getLogger(__name__)\\r\\n\\r\\n\\r\\nclass MoodAnalyzer:\\r\\n    \"\"\"Analyzes mood/emotion from text using NLTK VADER and custom rules\"\"\"\\r\\n\\r\\n    def __init__(self):\\r\\n        # Define emotion keywords for better classification\\r\\n        self.emotion_keywords = {\\r\\n            \\'happy\\': [\\'happy\\', \\'joy\\', \\'excited\\', \\'amazing\\', \\'wonderful\\', \\'great\\', \\'fantastic\\', \\'awesome\\', \\'pleased\\',\\r\\n                      \\'delighted\\'],\\r\\n            \\'sad\\': [\\'sad\\', \\'depressed\\', \\'unhappy\\', \\'miserable\\', \\'gloomy\\', \\'down\\', \\'blue\\', \\'melancholy\\'],\\r\\n            \\'angry\\': [\\'angry\\', \\'mad\\', \\'furious\\', \\'irritated\\', \\'annoyed\\', \\'rage\\', \\'upset\\', \\'frustrated\\'],\\r\\n            \\'fear\\': [\\'afraid\\', \\'scared\\', \\'terrified\\', \\'anxious\\', \\'worried\\', \\'nervous\\', \\'panic\\', \\'frightened\\'],\\r\\n            \\'surprise\\': [\\'surprised\\', \\'shocked\\', \\'amazed\\', \\'astonished\\', \\'stunned\\', \\'unexpected\\'],\\r\\n            \\'disgust\\': [\\'disgusted\\', \\'revolted\\', \\'repulsed\\', \\'sick\\', \\'nauseated\\', \\'appalled\\']\\r\\n        }\\r\\n\\r\\n    def analyze_emotion(self, text):\\r\\n        \"\"\"Analyze emotion from text\"\"\"\\r\\n        text_lower = text.lower()\\r\\n\\r\\n        # Get VADER sentiment scores\\r\\n        scores = sia.polarity_scores(text)\\r\\n\\r\\n        # Count emotion keywords\\r\\n        emotion_counts = {}\\r\\n        for emotion, keywords in self.emotion_keywords.items():\\r\\n            count = sum(1 for keyword in keywords if keyword in text_lower)\\r\\n            if count > 0:\\r\\n                emotion_counts[emotion] = count\\r\\n\\r\\n        # Determine emotion based on keywords and sentiment\\r\\n        if emotion_counts:\\r\\n            dominant_emotion = max(emotion_counts, key=emotion_counts.get)\\r\\n            return dominant_emotion\\r\\n\\r\\n        # Fallback to sentiment analysis\\r\\n        compound_score = scores[\\'compound\\']\\r\\n        if compound_score >= 0.5:\\r\\n            return \\'happy\\'\\r\\n        elif compound_score <= -0.5:\\r\\n            return \\'sad\\'\\r\\n        elif compound_score <= -0.1:\\r\\n            return \\'sad\\'\\r\\n        elif compound_score >= 0.1:\\r\\n            return \\'happy\\'\\r\\n        else:\\r\\n            return \\'neutral\\'\\r\\n\\r\\n\\r\\nclass CrisisDetector:\\r\\n    \"\"\"Detects crisis situations from text using keyword matching and sentiment analysis\"\"\"\\r\\n\\r\\n    def __init__(self):\\r\\n        # Crisis keywords (self-harm, suicide, violence indicators)\\r\\n        self.crisis_keywords = [\\r\\n            \\'suicide\\', \\'kill myself\\', \\'end my life\\', \\'hurt myself\\', \\'self harm\\',\\r\\n            \\'want to die\\', \\'better off dead\\', \\'no point living\\', \\'hopeless\\',\\r\\n            \\'can\\\\\\'t go on\\', \\'end it all\\', \\'take my life\\', \\'harm myself\\',\\r\\n            \\'cut myself\\', \\'overdose\\', \\'jump off\\', \\'hanging myself\\',\\r\\n            \\'worthless\\', \\'useless\\', \\'burden\\', \\'everyone would be better\\',\\r\\n            \\'plan to hurt\\', \\'plan to kill\\', \\'thoughts of death\\'\\r\\n        ]\\r\\n\\r\\n        # Severity weights for different phrases\\r\\n        self.severity_weights = {\\r\\n            \\'suicide\\': 0.9,\\r\\n            \\'kill myself\\': 0.9,\\r\\n            \\'hurt myself\\': 0.7,\\r\\n            \\'hopeless\\': 0.6,\\r\\n            \\'worthless\\': 0.5,\\r\\n            \\'can\\\\\\'t go on\\': 0.7,\\r\\n            \\'want to die\\': 0.8\\r\\n        }\\r\\n\\r\\n    def detect_crisis(self, text):\\r\\n        \"\"\"Detect if text indicates a crisis situation\"\"\"\\r\\n        text_lower = text.lower()\\r\\n\\r\\n        # Check for direct crisis keywords\\r\\n        crisis_score = 0\\r\\n        found_keywords = []\\r\\n\\r\\n        for keyword in self.crisis_keywords:\\r\\n            if keyword in text_lower:\\r\\n                found_keywords.append(keyword)\\r\\n                crisis_score += self.severity_weights.get(keyword, 0.5)\\r\\n\\r\\n        # Get sentiment analysis\\r\\n        scores = sia.polarity_scores(text)\\r\\n\\r\\n        # Combine keyword detection with extreme negative sentiment\\r\\n        if found_keywords or (scores[\\'compound\\'] <= -0.8 and scores[\\'neg\\'] >= 0.6):\\r\\n            return True\\r\\n\\r\\n        # Additional check for high crisis score\\r\\n        if crisis_score >= 0.7:\\r\\n            return True\\r\\n\\r\\n        return False\\r\\n\\r\\n\\r\\nclass TextSummarizer:\\r\\n    \"\"\"Summarizes text using extractive summarization\"\"\"\\r\\n\\r\\n    def __init__(self):\\r\\n        pass\\r\\n\\r\\n    def summarize(self, text, max_sentences=3):\\r\\n        \"\"\"Create extractive summary of text\"\"\"\\r\\n        # Tokenize into sentences\\r\\n        sentences = sent_tokenize(text)\\r\\n\\r\\n        # If text is short, return as is\\r\\n        if len(sentences) <= max_sentences:\\r\\n            return text.strip()\\r\\n\\r\\n        # Calculate sentence scores based on word frequency\\r\\n        word_freq = self._calculate_word_frequency(text)\\r\\n        sentence_scores = self._score_sentences(sentences, word_freq)\\r\\n\\r\\n        # Get top sentences\\r\\n        top_sentences = heapq.nlargest(max_sentences, sentence_scores, key=sentence_scores.get)\\r\\n\\r\\n        # Sort by original order and join\\r\\n        top_sentences.sort(key=lambda x: sentences.index(x))\\r\\n        summary = \\' \\'.join(top_sentences)\\r\\n\\r\\n        return summary.strip()\\r\\n\\r\\n    def _calculate_word_frequency(self, text):\\r\\n        \"\"\"Calculate word frequency for scoring\"\"\"\\r\\n        words = word_tokenize(text.lower())\\r\\n        words = [word for word in words if word.isalnum() and word not in stop_words]\\r\\n        return Counter(words)\\r\\n\\r\\n    def _score_sentences(self, sentences, word_freq):\\r\\n        \"\"\"Score sentences based on word frequency\"\"\"\\r\\n        sentence_scores = {}\\r\\n\\r\\n        for sentence in sentences:\\r\\n            words = word_tokenize(sentence.lower())\\r\\n            words = [word for word in words if word.isalnum() and word not in stop_words]\\r\\n\\r\\n            if len(words) > 0:\\r\\n                score = sum(word_freq.get(word, 0) for word in words) / len(words)\\r\\n                sentence_scores[sentence] = score\\r\\n\\r\\n        return sentence_scores\\r\\n\\r\\n\\r\\n# Initialize analyzers\\r\\nmood_analyzer = MoodAnalyzer()\\r\\ncrisis_detector = CrisisDetector()\\r\\ntext_summarizer = TextSummarizer()\\r\\n\\r\\n\\r\\n@app.route(\\'/\\', methods=[\\'GET\\'])\\r\\ndef home():\\r\\n    \"\"\"Home endpoint with API documentation\"\"\"\\r\\n    return jsonify({\\r\\n        \"message\": \"MoodDecode NLP API\",\\r\\n        \"version\": \"1.0\",\\r\\n        \"endpoints\": {\\r\\n            \"POST /analyze_mood\": \"Analyze emotion from text\",\\r\\n            \"POST /detect_crisis\": \"Detect crisis situations\",\\r\\n            \"POST /summarize\": \"Summarize text content\"\\r\\n        },\\r\\n        \"example_usage\": {\\r\\n            \"analyze_mood\": {\\r\\n                \"input\": {\"text\": \"I feel amazing today!\"},\\r\\n                \"output\": {\"emotion\": \"happy\"}\\r\\n            },\\r\\n            \"detect_crisis\": {\\r\\n                \"input\": {\"text\": \"I\\'m feeling hopeless and might hurt myself\"},\\r\\n                \"output\": {\"crisis_detected\": True}\\r\\n            },\\r\\n            \"summarize\": {\\r\\n                \"input\": {\"text\": \"Long paragraph here...\"},\\r\\n                \"output\": {\"summary\": \"Condensed version...\"}\\r\\n            }\\r\\n        }\\r\\n    })\\r\\n\\r\\n\\r\\n@app.route(\\'/analyze_mood\\', methods=[\\'POST\\'])\\r\\ndef analyze_mood():\\r\\n    \"\"\"Analyze mood/emotion from input text\"\"\"\\r\\n    try:\\r\\n        data = request.get_json()\\r\\n\\r\\n        if not data or \\'text\\' not in data:\\r\\n            return jsonify({\"error\": \"Missing \\'text\\' field in request\"}), 400\\r\\n\\r\\n        text = data[\\'text\\']\\r\\n        if not text.strip():\\r\\n            return jsonify({\"error\": \"Text cannot be empty\"}), 400\\r\\n\\r\\n        emotion = mood_analyzer.analyze_emotion(text)\\r\\n\\r\\n        logger.info(f\"Mood analysis - Input: {text[:50]}... -> Emotion: {emotion}\")\\r\\n\\r\\n        return jsonify({\"emotion\": emotion})\\r\\n\\r\\n    except Exception as e:\\r\\n        logger.error(f\"Error in mood analysis: {str(e)}\")\\r\\n        return jsonify({\"error\": \"Internal server error\"}), 500\\r\\n\\r\\n\\r\\n@app.route(\\'/detect_crisis\\', methods=[\\'POST\\'])\\r\\ndef detect_crisis():\\r\\n    \"\"\"Detect crisis situations from input text\"\"\"\\r\\n    try:\\r\\n        data = request.get_json()\\r\\n\\r\\n        if not data or \\'text\\' not in data:\\r\\n            return jsonify({\"error\": \"Missing \\'text\\' field in request\"}), 400\\r\\n\\r\\n        text = data[\\'text\\']\\r\\n        if not text.strip():\\r\\n            return jsonify({\"error\": \"Text cannot be empty\"}), 400\\r\\n\\r\\n        crisis_detected = crisis_detector.detect_crisis(text)\\r\\n\\r\\n        logger.info(f\"Crisis detection - Input: {text[:50]}... -> Crisis: {crisis_detected}\")\\r\\n\\r\\n        return jsonify({\"crisis_detected\": crisis_detected})\\r\\n\\r\\n    except Exception as e:\\r\\n        logger.error(f\"Error in crisis detection: {str(e)}\")\\r\\n        return jsonify({\"error\": \"Internal server error\"}), 500\\r\\n\\r\\n\\r\\n@app.route(\\'/summarize\\', methods=[\\'POST\\'])\\r\\ndef summarize():\\r\\n    \"\"\"Summarize input text\"\"\"\\r\\n    try:\\r\\n        data = request.get_json()\\r\\n\\r\\n        if not data or \\'text\\' not in data:\\r\\n            return jsonify({\"error\": \"Missing \\'text\\' field in request\"}), 400\\r\\n\\r\\n        text = data[\\'text\\']\\r\\n        if not text.strip():\\r\\n            return jsonify({\"error\": \"Text cannot be empty\"}), 400\\r\\n\\r\\n        summary = text_summarizer.summarize(text)\\r\\n\\r\\n        logger.info(f\"Text summarization - Input length: {len(text)} -> Summary length: {len(summary)}\")\\r\\n\\r\\n        return jsonify({\"summary\": summary})\\r\\n\\r\\n    except Exception as e:\\r\\n        logger.error(f\"Error in text summarization: {str(e)}\")\\r\\n        return jsonify({\"error\": \"Internal server error\"}), 500\\r\\n\\r\\n\\r\\n@app.errorhandler(404)\\r\\ndef not_found(error):\\r\\n    return jsonify({\"error\": \"Endpoint not found\"}), 404\\r\\n\\r\\n\\r\\n@app.errorhandler(405)\\r\\ndef method_not_allowed(error):\\r\\n    return jsonify({\"error\": \"Method not allowed\"}), 405\\r\\n\\r\\n\\r\\nif __name__ == \\'__main__\\':\\r\\n    print(\"Starting MoodDecode NLP API...\")\\r\\n    print(\"Available endpoints:\")\\r\\n    print(\"  POST /analyze_mood - Analyze emotion from text\")\\r\\n    print(\"  POST /detect_crisis - Detect crisis situations\")\\r\\n    print(\"  POST /summarize - Summarize text content\")\\r\\n    print(\"\\\\nServer starting on http://localhost:5000\")\\r\\n\\r\\n    app.run(debug=True, host=\\'0.0.0.0\\', port=5000)'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "  from google.colab import files\n",
        "  files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask nltk pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMuZ-1Xi0y3x",
        "outputId": "64d80e41-28b0-4e8c-cbb8-a070617a2c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4AXyMeS05hn",
        "outputId": "2a188822-8214-4d02-dadb-96727c203991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken #add your authentication token here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxkG-aO71Xaw",
        "outputId": "5e610d45-0510-4b38-f7f6-67a41ab6f7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Open an HTTP tunnel on the default Flask port 5000\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\" * ngrok tunnel:\", public_url)\n",
        "\n",
        "# Now run your Flask app\n",
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gEv_hZO0_Ej",
        "outputId": "f1081412-7ebe-4a51-aaca-90ac1c735f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel: NgrokTunnel: \"https://5c20-34-106-64-117.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "Starting MoodDecode NLP API...\n",
            "Available endpoints:\n",
            "  POST /analyze_mood - Analyze emotion from text\n",
            "  POST /detect_crisis - Detect crisis situations\n",
            "  POST /summarize - Summarize text content\n",
            "\n",
            "Server starting on http://localhost:5000\n",
            " * Serving Flask app 'main'\n",
            " * Debug mode: on\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "Starting MoodDecode NLP API...\n",
            "Available endpoints:\n",
            "  POST /analyze_mood - Analyze emotion from text\n",
            "  POST /detect_crisis - Detect crisis situations\n",
            "  POST /summarize - Summarize text content\n",
            "\n",
            "Server starting on http://localhost:5000\n",
            "WARNING:werkzeug: * Debugger is active!\n",
            "INFO:werkzeug: * Debugger PIN: 132-529-403\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:05:57] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:05:57] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:06:12] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:07:07] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:07:42] \"\u001b[31m\u001b[1mGET /detect_crisis HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:__main__:Mood analysis - Input: I feel great!... -> Emotion: happy\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:12:36] \"POST /analyze_mood HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:12:50] \"\u001b[31m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:13:08] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:19:27] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:19:27] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:20:24] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:20:27] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:20:44] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:__main__:Mood analysis - Input: I feel great!... -> Emotion: happy\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:21:03] \"POST /analyze_mood HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:21:40] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:21:40] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:21:52] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:21:54] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:22:54] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:23:08] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:23:09] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:__main__:Mood analysis - Input: I feel great!... -> Emotion: happy\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:24:07] \"POST /analyze_mood HTTP/1.1\" 200 -\n",
            "INFO:__main__:Mood analysis - Input: I feel great!... -> Emotion: happy\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:24:59] \"POST /analyze_mood HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:25:31] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:27:41] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:__main__:Mood analysis - Input: I feel great!... -> Emotion: happy\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:27:49] \"POST /analyze_mood HTTP/1.1\" 200 -\n",
            "INFO:__main__:Crisis detection - Input: its so hard for me.om going to end my life... -> Crisis: True\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:29:47] \"POST /detect_crisis HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:30:25] \"\u001b[31m\u001b[1mGET /detect_crisis HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:31:16] \"\u001b[31m\u001b[1mGET /detect_crisis HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:31:19] \"\u001b[31m\u001b[1mGET /summarize HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Jun/2025 16:31:23] \"\u001b[31m\u001b[1mGET /analyze_mood HTTP/1.1\u001b[0m\" 405 -\n"
          ]
        }
      ]
    }
  ]
}